{
  "qformer_hidden_size": 768,
  "blocks_num": 6,
  "num_heads": 12,
  "num_object_queries": 32,
  "num_relation_queries": 64,
  "num_global_queries": 32,
  "num_reasoning_hops": 4,
  "num_relation_types": 16,
  "max_answer_length": 10,
  "num_epochs": 50,
  "batch_size": 24,
  "lr": 5e-5,
  "betas": [0.9, 0.999],
  "dropout_rate": 0.2,
  "weight_decay": 0.05,
  "eps": 1e-8,
  "sequence_size": 32,
  "unfreeze_layers": 0,
  "use_clip_for_text": true,
  "gradient_clip_norm": 1.0,
  "warmup_steps": 500,
  "patience": 10,
  "seed": 42,
  
  "num_workers": 4,
  "pin_memory": true,
  "precision": "bf16-mixed",
  
  "use_data_augmentation": true,
  "augmentation_prob": 0.3,

  "comments": {
    "description": "Config for Q-Former Improved on GQA Visual Reasoning dataset",
    "approach": "SGG + NSM with text generation and normalized exact match evaluation",
    "dataset": "lmms-lab/GQA (train_balanced, val_balanced, test_balanced)",
    "metric": "Normalized exact match accuracy",
    "batch_size": "Smaller due to SGG + NSM + generation memory requirements"
  }
}

